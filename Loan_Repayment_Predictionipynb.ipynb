{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Objective:\n",
        "Predicts whether the bank should approves the loan of an applicant based on his profit using Ensemble Learning Methods."
      ],
      "metadata": {
        "id": "mV9NsqlsHklO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loan Repayment Prediction Using Ensemble Learning Methods"
      ],
      "metadata": {
        "id": "BHA3Xm8LHgZw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries"
      ],
      "metadata": {
        "id": "c4lNWfHJHny9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "kFold = StratifiedKFold(n_splits=5)\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from  sklearn.metrics  import  accuracy_score , precision_score , recall_score,confusion_matrix,classification_report"
      ],
      "metadata": {
        "id": "LHJKMP-QHr_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reading file"
      ],
      "metadata": {
        "id": "mGnB4-9QHuNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/loan_data.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "2H2LPVUGHwlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Consise Summery\n",
        "\n",
        "df.info()"
      ],
      "metadata": {
        "id": "DZ7KnIB1H5s6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see that attribute purpose has object datatype. We need to deal with it."
      ],
      "metadata": {
        "id": "7mfM56FKH_9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Summery\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "-3dyWMy4IAeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Checking For Null Values"
      ],
      "metadata": {
        "id": "i2c_YmGlIGvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum().sum()"
      ],
      "metadata": {
        "id": "jPcNDJTWIEoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Our DataFrame contain Zero Null values.\n",
        "\n",
        "Now lets solve the problem with Purpose Attribute."
      ],
      "metadata": {
        "id": "7LjYgO6UIR5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# unique values in purpose attribute\n",
        "\n",
        "df.purpose.value_counts()"
      ],
      "metadata": {
        "id": "zmqeIAOEIXx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#It has 6 unique values. lets convert these labels into numeric form."
      ],
      "metadata": {
        "id": "gUTLVagqIcRp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Encoding\n",
        "We will be using Label Encoder to convert labels available in purpose attribute.\n",
        "\n",
        "It will Encode purpose labels with value between 0 and n_classes-1(5)."
      ],
      "metadata": {
        "id": "Oyc2IQ_TIgiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df['purpose']=LabelEncoder().fit_transform(df['purpose'])\n",
        "df.head()"
      ],
      "metadata": {
        "id": "KOVgKo-vIeZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Visualization"
      ],
      "metadata": {
        "id": "5gvDztU0Inns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_style('darkgrid')\n",
        "plt.hist(df['fico'].loc[df['credit.policy']==1], bins=30, label='Credit.Policy=1')\n",
        "plt.hist(df['fico'].loc[df['credit.policy']==0], bins=30, label='Credit.Policy=0')\n",
        "plt.legend()\n",
        "plt.xlabel('FICO')"
      ],
      "metadata": {
        "id": "Wr7Ua9eBIqMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "df[df['not.fully.paid']==1]['fico'].hist(bins=30, alpha=0.5, color='blue', label='not.fully.paid=1')\n",
        "df[df['not.fully.paid']==0]['fico'].hist(bins=30, alpha=0.5, color='green', label='not.fully.paid=0')\n",
        "plt.legend()\n",
        "plt.xlabel('FICO')"
      ],
      "metadata": {
        "id": "SP2EAVUcItN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#creating a countplot to see the counts of purpose of loans by not.fully.paid\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.countplot(data=df, x='purpose', hue='not.fully.paid')"
      ],
      "metadata": {
        "id": "KhxccyqpIw6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#checking the trend between FICO and the interest rate\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.jointplot(x='fico', y='int.rate', data=df)"
      ],
      "metadata": {
        "id": "JYMk6dU7I0Nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#understanding the relationship between credit.policy and not.fully.paid\n",
        "sns.lmplot(data=df, x='fico', y='int.rate', hue='credit.policy', col='not.fully.paid', palette='Set2')"
      ],
      "metadata": {
        "id": "Nq_BlBNoI3KK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.figure(figsize = (20, 15))\n",
        "sns.heatmap(df.corr(), cmap='BuPu', annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lZdrUNk8I54h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#We can see that init rate, credit policy, fico and inq.last.6mths has corresponding grater impact on target class(not.gully.paid)"
      ],
      "metadata": {
        "id": "ND5culOkI9NO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#\n",
        "Train-Test Split\n",
        "Splitting the dataset for training and testing purpose."
      ],
      "metadata": {
        "id": "QmO5WKQTI_eh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Dropping target class\n",
        "\n",
        "X = df.drop('not.fully.paid',axis=1)\n",
        "y = df['not.fully.paid']"
      ],
      "metadata": {
        "id": "d9_l8R_AJAe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=101)\n",
        ""
      ],
      "metadata": {
        "id": "o1riyV63JQMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modellng\n",
        "Decision Tree"
      ],
      "metadata": {
        "id": "uFsSZmk4JSwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "param_grid = {'max_depth': [2,3, 4,5,6,7,8,9,10,11,13,15,20]}\n",
        "\n",
        "grid_search = GridSearchCV(dt_clf, param_grid, scoring = 'recall_weighted',cv=kFold, return_train_score=True)\n",
        "grid_search.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "jsMJK8R7JWR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "grid_search.best_params_"
      ],
      "metadata": {
        "id": "QTuBYf0_JZC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dt_clf = DecisionTreeClassifier(max_depth=2)\n",
        "dt_clf.fit(X_train, y_train)\n",
        "y_pred_train = dt_clf.predict(X_train)\n",
        "y_pred_test = dt_clf.predict(X_test)\n",
        "\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)"
      ],
      "metadata": {
        "id": "nHphAF6lJbIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Confusion Matrix \\n\",confusion_matrix(y_test,y_pred_test))\n",
        "print(\"\\n\")\n",
        "print(\"<-------------------Classification Report---------------------->\\n\")\n",
        "print(classification_report(y_test,y_pred_test))\n",
        "print(\"\\n\")\n",
        "print(\"<---------------Accuracy Scores------------------->\\n\")\n",
        "print('Train Accuracy score: ',train_accuracy)\n",
        "print('Test Accuracy score:',test_accuracy)"
      ],
      "metadata": {
        "id": "pB-yc5GoJeuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#We got Accuracy of 84.58% using Decision Tree Classifier."
      ],
      "metadata": {
        "id": "gZgz3_dgJmcA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Bagging with Decision Tree"
      ],
      "metadata": {
        "id": "XBYwjyYWJwOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scaler=StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "bag_dt = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=2),n_estimators=100,bootstrap=True)\n",
        "score = cross_val_score(estimator=bag_dt, X=X_scaled, y=y, scoring='recall_weighted', cv=kFold, n_jobs=-1)\n",
        "print('Mean score:', score.mean())"
      ],
      "metadata": {
        "id": "P7I9npfxJiS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Bagging is not improving the score of model and giving only 73.10% of mean Score."
      ],
      "metadata": {
        "id": "Z4yIaNViJ6Ic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#AdaBoosting with Decision Tree"
      ],
      "metadata": {
        "id": "axdy3J6qJ9cf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "adaboost_clf = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(max_depth=2), learning_rate = 0.5)\n",
        "adaboost_clf.fit(X_train, y_train)\n",
        "print('Train score: {0:0.2f}'.format(adaboost_clf.score(X_train, y_train)))\n",
        "print('Test score: {0:0.2f}'.format(adaboost_clf.score(X_test, y_test)))"
      ],
      "metadata": {
        "id": "hhu-1le8J_ZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It giving the same result of 84% and not improving our Model."
      ],
      "metadata": {
        "id": "Hj7MWnC-KB-O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Random Forest Classifier"
      ],
      "metadata": {
        "id": "yzQhT3g9KD8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn"
      ],
      "metadata": {
        "id": "uo-NoyvbKVTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "jPF35ZAQKemD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_clf = RandomForestClassifier(n_estimators=600)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "y_pred_train = rf_clf.predict(X_train)\n",
        "y_pred_test = rf_clf.predict(X_test)\n",
        "\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)"
      ],
      "metadata": {
        "id": "NYhC-YICKGoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We got the Accuracy of 84.7% with random Forest Classifier"
      ],
      "metadata": {
        "id": "oSUfGlEyKn3h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#AdaBoosting with RandomForest"
      ],
      "metadata": {
        "id": "1oRxKur7K3nH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "adaboost_clf = AdaBoostClassifier(base_estimator = rf_clf, learning_rate = 0.5)\n",
        "adaboost_clf.fit(X_train, y_train)\n",
        "#print('Train score: {0:0.2f}'.format(adaboost_clf.score(X_train, y_train)))\n",
        "#print('Test score: {0:0.2f}'.format(adaboost_clf.score(X_test, y_test)))\n",
        "y_pred_train = adaboost_clf.predict(X_train)\n",
        "y_pred_test = adaboost_clf.predict(X_test)\n",
        "\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)"
      ],
      "metadata": {
        "id": "L2abDCt-K8NI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Confusion Matrix \\n\",confusion_matrix(y_test,y_pred_test))\n",
        "print(\"\\n\")\n",
        "print(\"<-------------------Classification Report---------------------->\\n\")\n",
        "print(classification_report(y_test,y_pred_test))\n",
        "print(\"\\n\")\n",
        "print(\"<---------------Accuracy Scores------------------->\\n\")\n",
        "#print('Train Accuracy score: ',train_accuracy)\n",
        "print('Test Accuracy score:',test_accuracy)"
      ],
      "metadata": {
        "id": "UM5pgECTK-4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Gradient Boosting"
      ],
      "metadata": {
        "id": "BB-Ws5kjLMdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "gb_clf = GradientBoostingClassifier(learning_rate = 0.05)\n",
        "gb_clf.fit(X_train, y_train)\n",
        "#print('Train score: {0:0.2f}'.format(gb_clf.score(X_train, y_train)))\n",
        "#print('Test score: {0:0.2f}'.format(gb_clf.score(X_test, y_test)))\n",
        "y_pred_train = gb_clf.predict(X_train)\n",
        "y_pred_test = gb_clf.predict(X_test)\n",
        "\n",
        "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)"
      ],
      "metadata": {
        "id": "mg2wIr10LLwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Confusion Matrix \\n\",confusion_matrix(y_test,y_pred_test))\n",
        "print(\"\\n\")\n",
        "print(\"<-------------------Classification Report---------------------->\\n\")\n",
        "print(classification_report(y_test,y_pred_test))\n",
        "print(\"\\n\")\n",
        "print(\"<---------------Accuracy Scores------------------->\\n\")\n",
        "#print('Train Accuracy score: ',train_accuracy)\n",
        "print('Test Accuracy score:',test_accuracy)"
      ],
      "metadata": {
        "id": "Vqsc6_pwLUmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "While Computing different Ensemble Learning Technologies, We Found that Most of the Bagging and Boosting algo are giving similar result with minimum difference in accuracy. Even though in all these Ensembles-\n",
        "\n",
        "We Found that the Best Model for this DataSet is Random Forest with Accuracy of 85%."
      ],
      "metadata": {
        "id": "BN_taibXLaGC"
      }
    }
  ]
}